{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing the training set\n",
    "dataset_train = pd.read_csv('./GoogleStocks.csv')\n",
    "df = dataset_train[['low','high','volume','open']]\n",
    "df = df.iloc[1:,:]\n",
    "df['low'] = pd.to_numeric(df['low'], errors='coerce')\n",
    "df['high'] = pd.to_numeric(df['high'], errors='coerce')\n",
    "df['varience'] = df[['low','high']].mean(axis=1)\n",
    "df['volume'] = pd.to_numeric(df['volume'],errors='coerce')\n",
    "df = df[['volume','varience','open']]\n",
    "# # df\n",
    "# training_set = df[['volume','varience','open']].values\n",
    "# training_set_scaled = training_set;\n",
    "\n",
    "\n",
    "y_adm = df['open']\n",
    "X_adm = df[['volume','varience']]\n",
    "X_adm_train,X_adm_val,y_adm_train,y_adm_val=train_test_split(X_adm,y_adm,test_size=0.2,random_state=42)\n",
    "X_adm_train=X_adm_train.values\n",
    "X_adm_val=X_adm_val.values\n",
    "y_adm_train=y_adm_train.values\n",
    "y_adm_val=y_adm_val.values\n",
    "# print(X_adm_train)\n",
    "# print(y_adm_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN1(num_hidden_layers,num_cells,num_timestamps):\n",
    "    # Initialising the RNN\n",
    "    # Creating a data structure with 10 timesteps and 1 output\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    training_set_scaled = X_adm_train;\n",
    "    for i in range(10, training_set_scaled.shape[0]):\n",
    "        X_train.append(training_set_scaled[i-10:i, 0:2])\n",
    "        y_train.append(y_adm_train[i])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    regressor = Sequential()\n",
    "\n",
    "    # Adding the first LSTM layer and some Dropout regularisation\n",
    "    regressor.add(LSTM(units = num_cells, return_sequences = True, input_shape = (X_train.shape[1], 2)))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    # Adding a second LSTM layer and some Dropout regularisation\n",
    "    regressor.add(LSTM(units = num_cells, return_sequences = True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    # Adding a third LSTM layer and some Dropout regularisation\n",
    "    if(num_hidden_layers==3):\n",
    "        regressor.add(LSTM(units = num_cells, return_sequences = True))\n",
    "        regressor.add(Dropout(0.2))\n",
    "\n",
    "    # Adding the output layer\n",
    "    regressor.add(Dense(units = 1))\n",
    "\n",
    "    # Compiling the RNN\n",
    "    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "    # Fitting the RNN to the Training set\n",
    "    regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)\n",
    "    \n",
    "    test_set_scaled = X_adm_val;\n",
    "#     sc = MinMaxScaler(feature_range = (0, 1))\n",
    "#     test_set_scaled = sc.fit_transform(test_set_scaled)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for i in range(10, test_set_scaled.shape[0]):\n",
    "        X_test.append(test_set_scaled[i-10:i, 0:2])\n",
    "        y_test.append(y_adm_val[i])\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "\n",
    "    print(X_test.shape)\n",
    "    \n",
    "    predicted_stock_price = regressor.predict(X_test)\n",
    "    # predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "    print(predicted_stock_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_7 to have 3 dimensions, but got array with shape (594, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-ddeec542e6d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRNN1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-134-f90ee9c479fc>\u001b[0m in \u001b[0;36mRNN1\u001b[0;34m(num_hidden_layers, num_cells, num_timestamps)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Fitting the RNN to the Training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtest_set_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_adm_val\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_7 to have 3 dimensions, but got array with shape (594, 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "RNN1(2,30,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 10, 2)\n",
      "[[104.783936]\n",
      " [104.783875]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.78389 ]\n",
      " [104.783936]\n",
      " [104.783936]\n",
      " [104.78389 ]\n",
      " [104.78381 ]\n",
      " [104.78381 ]\n",
      " [104.783844]\n",
      " [104.783905]\n",
      " [104.78389 ]\n",
      " [104.78389 ]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.78389 ]\n",
      " [104.783936]\n",
      " [104.78389 ]\n",
      " [104.78392 ]\n",
      " [104.78383 ]\n",
      " [104.78386 ]\n",
      " [104.783875]\n",
      " [104.783905]\n",
      " [104.783844]\n",
      " [104.783875]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.78389 ]\n",
      " [104.78386 ]\n",
      " [104.78389 ]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.783844]\n",
      " [104.78386 ]\n",
      " [104.783875]\n",
      " [104.78392 ]\n",
      " [104.783905]\n",
      " [104.783905]\n",
      " [104.783875]\n",
      " [104.78389 ]\n",
      " [104.78392 ]\n",
      " [104.783936]\n",
      " [104.783936]\n",
      " [104.78389 ]\n",
      " [104.78383 ]\n",
      " [104.78389 ]\n",
      " [104.78389 ]\n",
      " [104.783936]\n",
      " [104.783936]\n",
      " [104.783905]\n",
      " [104.78386 ]\n",
      " [104.783905]\n",
      " [104.783875]\n",
      " [104.783936]\n",
      " [104.78389 ]\n",
      " [104.78389 ]\n",
      " [104.783936]\n",
      " [104.783905]\n",
      " [104.783936]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.783905]\n",
      " [104.78392 ]\n",
      " [104.783875]\n",
      " [104.78392 ]\n",
      " [104.783936]\n",
      " [104.783936]\n",
      " [104.783905]\n",
      " [104.78386 ]\n",
      " [104.783875]\n",
      " [104.78386 ]\n",
      " [104.783875]\n",
      " [104.783905]\n",
      " [104.783905]\n",
      " [104.78389 ]\n",
      " [104.783936]\n",
      " [104.783936]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.78395 ]\n",
      " [104.78392 ]\n",
      " [104.783875]\n",
      " [104.78392 ]\n",
      " [104.783905]\n",
      " [104.78386 ]\n",
      " [104.783905]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.783936]\n",
      " [104.78392 ]\n",
      " [104.783936]\n",
      " [104.78386 ]\n",
      " [104.78392 ]\n",
      " [104.783905]\n",
      " [104.78383 ]\n",
      " [104.78386 ]\n",
      " [104.78389 ]\n",
      " [104.78392 ]\n",
      " [104.783905]\n",
      " [104.78389 ]\n",
      " [104.783905]\n",
      " [104.78392 ]\n",
      " [104.78389 ]\n",
      " [104.783936]\n",
      " [104.78392 ]\n",
      " [104.783936]\n",
      " [104.783905]\n",
      " [104.783844]\n",
      " [104.783844]\n",
      " [104.78389 ]\n",
      " [104.783875]\n",
      " [104.783905]\n",
      " [104.78389 ]\n",
      " [104.78386 ]\n",
      " [104.783875]\n",
      " [104.783844]\n",
      " [104.783875]\n",
      " [104.783875]\n",
      " [104.783844]\n",
      " [104.78389 ]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.783936]\n",
      " [104.783936]\n",
      " [104.78392 ]\n",
      " [104.783905]\n",
      " [104.783875]\n",
      " [104.78389 ]\n",
      " [104.78389 ]\n",
      " [104.78392 ]\n",
      " [104.783905]\n",
      " [104.783875]\n",
      " [104.78389 ]\n",
      " [104.78392 ]\n",
      " [104.78392 ]\n",
      " [104.783905]\n",
      " [104.783905]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dataset_test = dataset_test.iloc[1:,:]\n",
    "# dataset_train = dataset_train.iloc[1:,:]\n",
    "# real_stock_price = dataset_test.iloc[1:, 3:4].values #all open values are real stock prices\n",
    "# # Getting the predicted stock price of 2017\n",
    "# dataset_total = pd.concat((dataset_train['open'], dataset_test['open']), axis = 0)\n",
    "# inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "# inputs = inputs.reshape(-1,1)\n",
    "# inputs = sc.transform(inputs)\n",
    "# X_test = []\n",
    "# for i in range(10, 76):\n",
    "#     X_test.append(inputs[i-10:i, 0])\n",
    "# X_test = np.array(X_test)\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(real_stock_price)\n",
    "# print(predicted_stock_price.shape)\n",
    "# plt.plot(real_stock_price, color = 'black', label = 'TATA Stock Price')\n",
    "# # plt.plot(predicted_stock_price, color = 'green', label = 'Predicted TATA Stock Price')\n",
    "# plt.title('TATA Stock Price Prediction')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('TATA Stock Price')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
